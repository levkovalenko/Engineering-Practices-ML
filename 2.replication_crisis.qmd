---
title: "Replication crisis"
author: "Lev Kovalenko"
format:
    revealjs:
        theme: dark
        self-contained: true
---
 
## В чем заключается кризис?
 
![](images/stats_vs_ml.jpeg){fig-align="center"}
 
::: {.notes}
Машинное обучение (МО) нашло применение в исследованиях всех областей науки и во многом заменило традиционную статистику. И хотя для анализа данных зачастую проще использовать именно МО, присущий этой технологии «подход чёрной коробки» вызывает серьёзные проблемы при интерпретации результатов.
 
Термин «кризис воспроизводимости» означает, что тревожно большое количество результатов научных экспериментов не нашли своего подтверждения при проведении тех же манипуляций другими группами учёных. Это может означать, что результаты, полученные в ходе изначальных работ, ошибочны. Согласно данным одного анализа, до 85 % всех проведённых в мире исследовательских работ в области биомедицины не привели к значимым результатам.
 
 
:::
 
## [Научный метод](https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D1%87%D0%BD%D1%8B%D0%B9_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4){preview-link="true"} проведения исследований
 
 
:::: {.columns}
 
::: {.column width="60%"}
![](images/scientific_method.png){fig-align="center"}
:::
 
::: {.column width="40%"}
- [Объективность](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D1%81%D1%82%D1%8C){preview-link="true"}
- [Воспроизводимость](https://ru.wikipedia.org/wiki/%D0%92%D0%BE%D1%81%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%B4%D0%B8%D0%BC%D0%BE%D1%81%D1%82%D1%8C){preview-link="true"}
- [Валидность](https://ru.wikipedia.org/wiki/%D0%92%D0%B0%D0%BB%D0%B8%D0%B4%D0%BD%D0%BE%D1%81%D1%82%D1%8C){preview-link="true"}
:::
 
::::
 
::: {.notes}
 
Собственно в научном сообществе есть методология проведения исследований и познания. Называется она научный метод. Основными требованиями к которому являются объективность, воспроизводимость и валидность.
 
Объекти́вность — отношение к объекту (явлению) и его характеристикам, процессам, как к независимому от воли и желания человека. Объективность подразумевает наличие знаний как таковых об объекте (явлении). Устойчивость объективности зависит от количества и точности понимания различных параметров объекта и/или процессов явления.
 
Воспроизводимость - главный принцип научного метода . Это означает, что результат, полученный в ходе эксперимента или наблюдательного исследования , должен быть снова достигнут с высокой степенью согласия, когда исследование повторяется с использованием одной и той же методологии разными исследователями. Только после одного или нескольких таких успешных повторений результат должен быть признан научным знанием.
 
Вали́дность — обоснованность и пригодность применения методик и результатов исследования в конкретных условиях. Более прикладное определение понятия «валидность» — мера соответствия методик и результатов исследования поставленным задачам.
 
Давайте уделим чуть больше внимания воспроизводимости. Так как сегодня мы рассматриваем кризис воспроизводимости.
:::
 
## Какая бывает воспроизводимость^[На основании определений [Ассоциации вычислительной техники](https://www.acm.org/publications/policies/artifact-review-badging)]?
 
- Повторяемость измерений(также сходимость результатов измерений, англ. Repeatability)
- Повторяемость исследований (англ. Replicability) (Different team, same experimental setup)
- Воспроизводимость (англ. Reproducibility)
 
::: aside
:::
 
::: {.notes}
На основании определений Ассоциации вычислительной техники я предлагаю принять следующие определения:
 
Повторяемость измерений(также сходимость результатов измерений, англ. Repeatability) (Same team, same experimental setup): Результат может быть получен с заявленной точностью одной и той же командой, используя одну и ту же процедуру измерения, одну и ту же измерительную систему, при одинаковых рабочих условиях, в одном месте при нескольких испытаниях. Для вычислительных экспериментов это означает, что исследователь может надежно повторить собственное вычисление.
 
Повторяемость исследований (англ. Replicability) (Different team, same experimental setup): Результат может быть получено с заявленной точностью другой командой с использованием той же процедуры измерения, той же измерительной системы, в тех же рабочих условиях, в том же или другом месте при нескольких испытаниях. Для вычислительных экспериментов это означает, что независимая группа может получить тот же результат, используя наработки автора, вплоть до его реализаций.
 
Воспроизводимость (англ. Reproducibility): Результат может быть получено с заявленной точностью другой командой, другой измерительной системой, в другом месте на нескольких испытаниях. Для вычислительных экспериментов это означает, что независимая группа может получить тот же результат, используя артефакты, которые они разрабатывают полностью независимо.
:::
 
## Что такое воспроизводимое исследование(ВИ)
 
>«Цель воспроизводимых исследований - привязать конкретные инструкции к анализу данных и экспериментальным данным, чтобы исследование можно было воссоздать, лучше понять и проверить».
 
::: {.notes}
Воспроизводимые исследования (Reproducible research) - это термин, используемый в некоторых областях исследований для обозначения определенного способа проведения анализа, который предоставляет:
 
- инструменты преобразующие необработанные данные и метаданные в обработанные данные;
- инструменты выполняющие анализ данных;
- инструменты агрегирующие анализы в отчет.
 
В некоторых случаях указывают конкретно какие инструменты и шаги имеются в виду, это может быть программный продукт, публикации, определенные лабораторные условия и т.д.
 
Когда предоставляются объекты анализа, например данные, и инструменты, а также алгоритмы последовательного решения задачи, это позволяет другим исследователям:
 
- выполнять анализ, о котором не сообщалось первыми исследователями;
- проверить правильность исследований, выполненных первыми исследователями;
:::
 
## В чем причина кризиса воспроизводимости?{.smaller}
 
:::: {.columns}
 
::: {.column width="40%"}
- недостаточное понимание алгоритма ML.
- недостаточное знакомство с исходными данными.
- неверная интерпретация результатов.
:::
 
::: {.column width="60%"}
![](images/expenses-in-usa.png){fig-align="center"}
![](images/number-of-divorces.png){fig-align="center"}
:::
::::
 
::: {.notes}
Недостаточное понимание алгоритма — очень распространённая проблема в машинном обучении. Это серьезная проблема при работе с нейросетями ввиду множества параметров (зачастую для глубоких нейросетей количество параметров может составлять миллионы). Помимо этих параметров надо принимать в расчёт и гиперпараметры — такие, как скорость обучения, метод инициализации, количество итераций, архитектура нейросети.
 
Для решения проблемы мало осознать, что исследователь недостаточно хорошо понимает работу алгоритма. Как можно сравнить результаты, если в разных работах применялись отличающиеся по структуре нейронные сети? Многослойная нейронная сеть имеет очень сложную динамическую структуру. Поэтому даже добавление единственной переменной или смена одного гиперпараметра может значительно повлиять на результаты.
 
Плохое понимание исходных данных также является серьёзной проблемой, но эта проблема существовала и во время работы с традиционными статистическими методами. Ошибки в сборе данных — такие, как ошибки квантования, неточности считывания и использование замещающих переменных — самые распространённые затруднения. Субоптимальные данные всегда будут проблемой, но понимать, какой алгоритм применить к какому типу данных — невероятно важно, это значительно повлияет на результат.
 
 
Ошибочная оценка результатов может быть весьма распространена в научном мире. Одна из причин — видимая корреляция не всегда отражает реальную взаимосвязь. Есть несколько причин, почему переменные А и B могут коррелировать:
 
- A может изменяться при изменении B;
- B может изменяться при изменении A;
- A и B могут изменяться при изменении общей базовой переменной, C;
- корреляция A и B может быть ложной.
Продемонстрировать корреляцию двух значений легко, гораздо сложнее определить её причину. Погуглив «spurious correlations» (ложная корреляция), вы найдёте весьма интересные и забавные примеры, имеющие статистическое значение:
 
собственно на слайде вы можете видеть некоторые из них, например расходы США на науку, космос и технологии явно коррелируют с самоубийствами путем повешения, а от количества разводов в Мэне зависит потребление маргарина на душу населения.
 
Всё это может выглядеть забавными совпадениями, но смысл в том, что алгоритм машинного обучения, обработав эти переменные единым набором, воспримет их как взаимозависимые, не подвергая эту зависимость сомнению. То есть алгоритм будет неточным или ошибочным, поскольку ПО выделит в датасете паттерны, которых не существует в реальном мире.
Это примеры ложных корреляций, которые в последние годы опасно распространились в связи с использованием наборов данных из тысяч переменных.
 
Так же есть такие техники как p-hacking или форсирование корреляций.
 
Суть p-hacking’а состоит в дотошном поиске в наборе данных статистически значимых корреляций и принятии их за научно обоснованные.
 
Ещё одна проблема алгоритмов машинного обучения заключается в том, что алгоритм должен делать предположения. Алгоритм не может «ничего не найти». Это означает, что алгоритм либо найдёт способ интерпретировать данные независимо от того, насколько они соотносятся между собой, либо не придёт к какому-либо определённому заключению (обычно это означает, что алгоритм был неверно настроен или данные плохо подготовлены).
 
:::
 
 
# Стоит ли использовать машинное обучение?
 
::: {.notes}
Хороший вопрос, раз его использование привело к кризису в научной среде, то оправдано ли его использование? (Конечно, да.)
 
Та же проблема всегда присутствовала при использовании традиционных статистических методов анализа. Она лишь усугубилась с появлением больших наборов данных и алгоритмов, которые находят корреляции автоматически и не настолько прозрачны, как стандартные методы. И это усиление выявило недостатки научного процесса, которые ещё предстоит преодолеть.
 
Машинное обучение упрощают анализ данных и алгоритмы ML делают за пользователя громадную работу. В тех областях, где учёные имеют дело с действительно большими объёмами данных, традиционные методы статистического анализа оказываются неэффективными и применение ML — единственный разумный способ обработки информации. Однако следует учитывать, что увеличение продуктивности работы за счёт ускорения анализа данных может быть скомпрометировано недостаточным качеством полученных прогнозов.
 
:::
 
## Правила проведения воспроизводимых исследований {.scrollable .smaller}
 
0. Для каждого полученного результата сохраните алгоритм его получения.
1. Избегайте этапов ручного управления данными или процессом.
2. Сохраните точные версии всех использованных внешних инструментов.
3. Используйте контроль версий.
4. Храните все промежуточные результаты в стандартизированном виде.
5. Для алгоритмов использующих случайность записывайте их random_state.
6. Всегда храните вместе с графиками данные.
7. Иерархический подход при генерировании результатов анализа.
8. Всегда указывайте вместе текстовые утверждения и результаты исследования.
9. Обеспечивайте доступность ваших результатов, данных и исследований.
 
::: {.notes}
0. Важно знать каким образом вы получили те или иные результаты. Знание того, как вы перешли от необработанных данных к заключению, позволяет вам: защищать, обновлять, воспроизводить и передавать свои результаты исследований.
 
1. Может возникнуть соблазн открыть файлы данных в редакторе и вручную исправить пару ошибок форматирования или удалить выбросы. Кроме того, современные редакторы позволяют легко форматировать файлы огромных размеров. Однако соблазну сократить ваш алгоритм следует сопротивляться. Ручная обработка данных — это скрытая манипуляция.
 
2. Вам необходимо задокументировать выпуск и версию всего используемого программного обеспечения, включая операционную систему. Незначительные изменения в программном обеспечении могут повлиять на результаты. В идеале вы должны настроить виртуальную машину или контейнер со всем программным обеспечением, используемым для запуска ваших скриптов. Это позволяет сделать снимок вашей аналитической экосистемы, что упрощает воспроизведение ваших результатов.
 
3. Для отслеживания версий ваших скриптов следует использовать систему контроля версий, такую ​​как Git. Вы должны пометить (сделать снимок) текущее состояние скриптов и ссылаться на этот тег во всех получаемых вами результатах. Если вы затем решите изменить свои алгоритмы, что вы обязательно сделаете, можно будет вернуться во времени и получить точные сценарии, которые использовались для получения заданного результата.
 
4. Если вы соблюдаете Правило № 1, в теории уже возможно воссоздать любые результаты на основе необработанных данных. Однако хотя это может быть теоретически возможно, на практике могут быть ограничивающие факторы. Проблемы могут быть следующие:
 
- отсутствие ресурсов для запуска результатов с нуля (например, если использовались значительные вычислительные ресурсы кластера)
- отсутствие лицензий на некоторые инструменты, если использовались коммерческие инструменты
- недостаточная техническая доступность некоторых инструментов
 
В этих случаях может быть полезно начать исследование с набора производных данных, которые уже могут представлять больше пользы или быть более удобными, чем необработанных данных. Хранение этих промежуточных наборов данных (например, в формате CSV) предоставляет больше возможностей для дальнейшего анализа и может упростить определение проблемных результатов, когда они ошибочны, поскольку нет необходимости все переделывать.
 
5. Одна вещь, которую специалисты по данным часто не могут сделать — это установить исходные значения для своего анализа. Это делает невозможным точное воссоздание исследований машинного обучения. Многие алгоритмы машинного обучения включают стохастический элемент, и, хотя надежные результаты могут быть статистически воспроизводимыми, нет ничего, что можно было бы сравнить с теплым сиянием в глазах проверяющего при точном совпадении результатов.
 
6. Если вы используете скриптовый язык программирования, ваши графики, скорее всего, автоматически. Однако если вы используете такой инструмент, как Excel, убедитесь, что вы сохранили начальные данные. Это позволяет не только воспроизвести график, но также более детально просмотреть лежащие в основе данные.
Также стоит всегда сохранять алгоритмы, которые вы использовали для получения графиков, на основе которых вы потом приводите какие-либо утверждения.
 
7. Наша задача как специалистов по обработке данных — обобщить данные в той или иной форме. Вот что включает в себя извлечение информации из данных.
Однако резюмирование также является простым способом неправильного использования данных, поэтому важно, чтобы заинтересованные стороны могли разбить сводку на отдельные точки данных. Для каждого итогового результата укажите ссылку на данные, использованные для расчета итогового значения.
 
8. В конце работы результаты анализа данных оформляются в текстовом виде. И слова неточны. Иногда бывает трудно определить связь между выводами и анализом. Поскольку отчет часто является самой важной частью исследования, важно, чтобы его можно было связать с результатами и, в соответствии с правилом № 1, с исходными данными.
 
9. В коммерческих условиях может быть нецелесообразно предоставлять открытый доступ ко всем данным. Однако имеет смысл предоставить доступ другим пользователям в вашей организации. Облачные системы управления исходным кодом, такие как Bitbucket и GitHub, позволяют создавать частные репозитории, к которым могут получить доступ любые авторизованные коллеги.
 
:::
 
## Заключение {.smaller}
 
Машинное обучение в науке представляет проблему из-за того, что результаты недостаточно воспроизводимы. Однако учёные в курсе этой проблемы и работают над моделями ML, дающими более воспроизводимый и прозрачный результат. Настоящий прорыв произойдет, когда эта задача будет решена для нейросети.
 
Как сказал физик Ричард Фейнман в своей речи перед выпускниками Калифорнийского технологического института в 1974 году:
 
>“Первый принцип науки заключается в том, чтобы не одурачить самого себя. И как раз себя-то одурачить проще всего.”
 
## Список источников
 
- [Кризис машинного обучения в научных исследованиях](https://tproger.ru/translations/machine-learning-crisis)
 
- [Reproducibility vs. Replicability: A Brief History of a Confused Terminology](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778115)
 
- [Repeatability, Repr)oducibility, and Replicability: Tackling the 3R challenge in biointerface science and engineering](https://avs.scitation.org/doi/full/10.1116/1.5093621)
 
- [10 RULES FOR CREATING REPRODUCIBLE RESULTS IN DATA SCIENCE](https://dataconomy.com/2017/07/10-rules-results-data-science/ )
