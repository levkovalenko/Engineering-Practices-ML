[
  {
    "objectID": "4.git_workflow.html#кратко-о-git",
    "href": "4.git_workflow.html#кратко-о-git",
    "title": "Git workflow",
    "section": "Кратко о git",
    "text": "Кратко о git\n\n\nВ кратце рассмотрим струтктуру git - популярную системы контроля версий. Она позволяет совместно работать над проектом множеству разработчиков. В большинстве workflow есть некоторый единый удаленный репозиторий, который хранит в себе все изменения от всех разработчиков. У каждого разработчкика есть локальный репозиторий, синхронизация репозиториев происходит с помощью push и fetch команд. Кроме локально репозитория у разработчика есть индекс (некоторая база отслеживающая файлы и изменения в них) и workspace. При создании нового файла его сначала нужно добавить в index командой git add, а потом создать коммит git commit. Откатиться на изменения в индексе или локальном репозитории можно командами checkout и checkout HEAD. Сравнить состояние workspace можно командами deff и diff HEAD. Команды pull и rebase позволяют подтягивать изменения с удаленного репозитория сразу и в локальный репозиторий, и в workspace. В целом это основной набор команд который вам пригодиться и ими вы чаще всего будете пользоваться при работе с git."
  },
  {
    "objectID": "4.git_workflow.html#какие-workflow-сущесвтуют",
    "href": "4.git_workflow.html#какие-workflow-сущесвтуют",
    "title": "Git workflow",
    "section": "Какие workflow сущесвтуют?",
    "text": "Какие workflow сущесвтуют?\n\ngitflow\ngithub flow\nforking workflow\ndata science lifecycle process\n\n\nСегодня мы рассмотрим 4 подхода: git, github, forking flow подходы используемые в разработке, data science lifecycle process это уже некоторая попытка адаптировать flow под исследования."
  },
  {
    "objectID": "4.git_workflow.html#gitflow",
    "href": "4.git_workflow.html#gitflow",
    "title": "Git workflow",
    "section": "Gitflow",
    "text": "Gitflow\n\n\nGitflow одна из первых методологий управления проектом направленное на переодиеские, не частые релизы. В ней есть основная ветка master, в которой хранятся все релизы. До релиза разрабатываемый код находится в ветке develop. Каждое нововведение (фичу) один разработчик разрабатывает в отдельной ветке, после этого она сливается с ветко develop. Когда выолнен весь объем фич для релиза, из develop создается ветка release, в которой ведеться доработка релиза и потом она вливается в master и тегируется, а также вливается в develop. Теги отвечают за версии релизов. В случае обнаружение багов в релизе появляется ветка hotfix в которой исправляются ошибки и она снова вливается в master и develop.\nКак видите, методология достаточно тяжеловесная и применима в основном в enterprise разработке, так как она подстраивается под большинство фреймверков управления проектов по водопадной модели. В исследваония применить такую методологию можно, но в результате вы получите очень много overhead для проекта по управлению ветками."
  },
  {
    "objectID": "4.git_workflow.html#github-flow",
    "href": "4.git_workflow.html#github-flow",
    "title": "Git workflow",
    "section": "Github flow",
    "text": "Github flow\n\n\nGithub flow это модификация gitflow предложенная github. Она направлена на снижение количества веток и упрощение поддерживания проекта. В ней оставется две вети - master и feature. Разработка новой функциональности проводится в отдельной фича-ветке, после этого происходит merge в master, после этого происходит новый релиз проекта.\nЭта методология построена для проектов управляемых в разлиных гибких методологиях. Одной из важных рекомендаций авторов, является открытие merge request заранее и обсуждение в нем рзличных моментов заранее, до окончания работ. В целом методология достаточно легковесная и гибкая, может подойти для проведения исследвоаний, но в исследваонии нет потребности в такой частоте релизов на начальных этапах."
  },
  {
    "objectID": "4.git_workflow.html#forking-workflow",
    "href": "4.git_workflow.html#forking-workflow",
    "title": "Git workflow",
    "section": "Forking workflow",
    "text": "Forking workflow\n\n\nForking workflow это методология поверх github workflow для разработки opensource проектов. Основная сложность в opesource связана с тем, что изначально доступа к изменению в репозитори проекта у потенциального контриьютора нет, поэтому ему предлагается следующая последовательность шагов:\n\nРазработчик «разветвляет» «официальный» серверный репозиторий. Это создает их собственную копию на стороне сервера.\nНовая серверная копия клонируется в их локальную систему.\nВ локальный клон добавлен удаленный путь Git для «официального» репозитория.\nСоздана новая локальная ветка функции.\nРазработчик вносит изменения в новую ветку.\nДля изменений создаются новые коммиты.\nВетвь помещается в собственную серверную копию разработчика.\nРазработчик открывает запрос на перенос из новой ветки в «официальный» репозиторий.\nЗапрос на перенос утверждается для слияния и объединяется в исходный серверный репозиторий.\n\nТаким образом организована разработка в opensource преоктах. Могу сказать, что данная методология для исследваоний подходит плохо, из неее можно позаимствовать идею раздельных репозиториев, что если в команде много исследвоателей, то возожно их нужно разнести по разным репозиториям и переодически вытаскивать полезные новвоведения в “официальный” репозиторий."
  },
  {
    "objectID": "4.git_workflow.html#data-branch",
    "href": "4.git_workflow.html#data-branch",
    "title": "Git workflow",
    "section": "Data branch",
    "text": "Data branch\n\n\nВвводятся различные ветки, например есть data branches, в которых реализуетс код для обработки данных, пишется отчет об этом и тесты для кода. На слайде представлена последовательность действий в такой ветке."
  },
  {
    "objectID": "4.git_workflow.html#explore-and-experiment-branches",
    "href": "4.git_workflow.html#explore-and-experiment-branches",
    "title": "Git workflow",
    "section": "Explore and experiment branches",
    "text": "Explore and experiment branches\n \n\nДля исследваония данных предлагется использовать explore branches. Эти ветки отсаются висеть в истории гита без мерджа, потому что код который проводит исследвоание нужен разово что бы подтвердить или опровергнуть гипотезу.\nДля экспериментов есть две стратегии, если эксперимент опроверг подход, то такая ветка не получает merge request и просто оставется висеть в истории, так как знания о неудачных экспериментах тоже важны и влияют на принятие следующих решений в развитии проекта.\nДля успешного эксперимента ветка переходит в ветку моделей."
  },
  {
    "objectID": "4.git_workflow.html#model-branches",
    "href": "4.git_workflow.html#model-branches",
    "title": "Git workflow",
    "section": "Model branches",
    "text": "Model branches\n\n\nКогда был найден удачный подход то появляется новая ветка model branch в которой происходит настрйока и исслделедование модели, а также написание отчетов и тестов. После этого происходит влитие ветки в master branch и релиз модели."
  },
  {
    "objectID": "4.git_workflow.html#хорошая-методология",
    "href": "4.git_workflow.html#хорошая-методология",
    "title": "Git workflow",
    "section": "Хорошая методология?",
    "text": "Хорошая методология?\n\n\nПлюсы\n\nВ основной ветке только важный код.\nСохраняется информация о всех исследваониях.\nИмеет “логичные” разделения веток для разных задач.\n\n\nМинусы\n\nСложно автоматизировать воспроизвдеение всех исследвланий.\nИнформация об исследованиях “размазана” по репозиторию.\nВ теории выглядит хорошо, а на практике…\n\n\n\n\nМетодолгия конечно не плохая, но сильно оторвана от реальности. По факту же в проекте большая часть работы связана с обработкой и подготовкой данных, так как чистые датасеты вы встретите только а kaggle, в реальности же придеться очень долго разбираться с данными и возваращаться к ним постоянно. Поэтому хотелось бы как-то просто обновлять результаты уже проведенных исследований.\nВ целом методология рабочая, но больше подходит для уже существующего проекта, где есть собранные и подготовленные датасеты и основной задачей является моделирование."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Engineering practices in ML",
    "section": "",
    "text": "Сайт для курса “Инженерные практики в ML”."
  },
  {
    "objectID": "3.team_work.html#общие-артефакты",
    "href": "3.team_work.html#общие-артефакты",
    "title": "Team work",
    "section": "Общие артефакты",
    "text": "Общие артефакты\n\n\nОбщие договренности.\n\n\n\n\nЗадачи, план исследований.\n\n\n\n\nКод, окружение, среда выполнения.\n\n\n\n\nЗнания(отчеты об исследвоаниях).\n\n\n\n\nИсходные, подготовленные данные и модели.\n\n\nВо-первых, это общие договоренности: ролевая модель, разлиные процессы, требвоания. То есть некоторые условности, которые приняты в команде, для решения спорных моментов и некоторой унификации артефактов, кода, задач и отчетов.\nВо-вторых, это задачи. В команде нужно как-то орагнизовать рабочий процесс, разделить отвественость и обязанности на членов команду, выбрать основные направления для исследования, определеить ключевые точки в исследвоаниях. Это все нужно сделать что бы каждый член команды знал что ему нужно делать, какие эксперименты проводить, какой код писать. При этом нужно организовать так что бы обязанности не дублировались или дублировались по минимуму.\nВ-третьих, код и окружение. Вам всем придеться писать код для экспериментов, преиспользовать его, поддерживать, переодиечески обновлять и перезапускать. Кроме написания кода, вам придеться этот код запускать, для этого нужно воспроизводимое окружение, а лучше общая инфраструктура.\nВ-четвертых, это знания полученные в ходе исследвания. Их нужно фиксировать, обновлять, версионировать и передавать команде. Вот например сотрудник проводил важные эксперименты, но вышел в отпуск или заболел, нужно как-то его знаня о проведенных исследваониях, полученных результатах и сформулированных выводах. Для всего этого надо как-то управлять знаниями.\nВ-пятых, нужно решить с большими и громоздкими артефактами - данными и моделями, их нужно как-то хранить и версионировать, а еще делиться с коллегами. Более того нужно писать такой код который бы выдавал воспроизводимые результаты, всегда один и тот же бинарный объект или массив данных."
  },
  {
    "objectID": "3.team_work.html#примеры-contributing",
    "href": "3.team_work.html#примеры-contributing",
    "title": "Team work",
    "section": "Примеры Contributing",
    "text": "Примеры Contributing\n\npython devguide\ncontribute to scipy\nsklearn contributing\ncontribute to tensorflow\n\n\nКак видите в них описывалось все, начиная от того, как развернуть проект, как оформить merge request, как написать документацию к изменениям, заканчивая часами работы core developers и тем как отвечать на вопросы в stack overflow.\nДовольно обширные своды правил и информации как разрабатывать проект. Такие практики стоит перенимать и задействовать в своих командах."
  },
  {
    "objectID": "3.team_work.html#что-стоит-включать-в-договренности",
    "href": "3.team_work.html#что-стоит-включать-в-договренности",
    "title": "Team work",
    "section": "Что стоит включать в договренности?",
    "text": "Что стоит включать в договренности?\n\nВсе где возникают разногласия в команде\n\n\nКак и куда писать код\nКак и куда писать тесты\nКак настроить среду разработки\nКак и куда писать документацию\nКак и куда сохранять данные\nКак и где составлять задачи\nКак брать задачу на себя\nКак оформлять merge requests\nКто за что отвечает\nУ кого можно получить помощь по процессам\nКакие инструменты можно и нельзя использоваться\nКак этими инструментами пользоваться\nКак организован CI в проекте\nЧто писать в комитах\nКак происходит починка багов\nКакой у проекта development cycle\nУ кого можно получить помощь по процессам\n\nи многое многое другое.\n\nВсе это стоит фиксировать и поддерживать в актуальном состоянии. Это полезно. Полезно по двум причинам:\n\nКейс первый. Вы работаете с Петей и Васей. Вы договорились с Васей писать код в стиле А и начали работать. Петя об этом не знает и пишет его по своему, в стиле Б. Когда вы объединяете свои наработки, у вас получается не консистетный код, в одном модуле функции и классы, в другом весь код написан в глобальной области как один скрипт. Получается что текущие наработки нужно будет рефакторить и приводить в порядок. А все это произошло потому что информация не была передана всем участникам команды. Если вы о чем-то договорились, то это стоит зафисксировать в общедоступном месте и донести до всех членов команды.\nКейс второй. К вам в команду пришел новый сотрудник. Для того что бы рассказать ему все ипомочь настроить проект вам потребуется несколько дней с ним общаться и передавать занния. При этом важно ничего не забыть. Но если все договоренности зафиксированы, то сотрудник сможет сам разобраться с этим и к вам придет уже с конкретными вопросами."
  },
  {
    "objectID": "3.team_work.html#резюме",
    "href": "3.team_work.html#резюме",
    "title": "Team work",
    "section": "Резюме",
    "text": "Резюме\n\nДоговоренности фиксируются в общедоступном месте.\nДоговоренности несут пользу процессу и членам команды.\nДоговоренности можно отменять, если они мешают команде."
  },
  {
    "objectID": "3.team_work.html#defenition-of-ready-dor",
    "href": "3.team_work.html#defenition-of-ready-dor",
    "title": "Team work",
    "section": "Defenition of ready (DoR)",
    "text": "Defenition of ready (DoR)\n\nМотивация появления задачи.\nПроверяемая гипотеза.\nНа каких данных проводить исследование.\nОписание действий для обаботки данных.\nКонкретный ожидаемый результат.\n\n\nВажно иметь список критериев описывающй состояние задачи, когда ее можно взять в работу. Поскольку задачи в проекте могут возникать не только от тимлида, но и от самих исследваотелей, так как во время эксперимента были выявлены какие-то аномалии в данных или же необхдимо проверить какие-то дополнительные гипотезы, нужно что бы такие договоренности были в команде и все могли формировать достаточно подробные задачи.\nВ задаче стоит указать, почему она вообще появилась и какой imapct она сделает для проекта, например в проекте по классификации электронных сообщений проводилось исследование по ключевым словам для каждой темы, в какой-то теме ключевыми словами стали зравствуте и привет, соотвественно в проекте появилась задача по удалению приветствий и в ней стоит упомянуть причину ее появления.\nНужно указать првоеряемую гипотезу, то есть что именно нужно проверить в ходе исследования. Например првоерить наличие зависимости между признаками, или выбор стратегии заполнения пропусков для такого-то признака, или выделение ключевых слов на оснвое какого-то подхода, или же построение такой-то модели на данных проекта.\nТак же важно указать какие данные стоит использовать в исследовании, потому что если в проекте хранятся промежуточные версии данных, то сложно с ходу разобраться, а какая из них нужна для проверки гипотезы.\nЕсли нет готовых данных или задача заключается в обработке данных, то нужно описать какие действия нужно прдпринять для подготовки данных, что бы исполнитель задачи не догадаывался как нужно объеденить два датасета что бы получилась корректная выборка.\nНу и последнее конкретный результат, то есть что вы ожидаете при выполнениее задачи, например, если вернутся к примеру про классификацию писем, то ожидаемый результат, что приветсвия пропадут из списков ключевы слов, или же какая-то модель получит более высокие метрики. То есть, что вы, как автор задачи, ожидаете после ее исполнения.\nЕсли вы как автор не можете сформулировать такую задачу и для нее нужны дополнительные знания, то стоит сначала создать задачу для получения этих знаний, например задача по выбору источника данных погоды или же задача по исследованию применения нейростей определенной архитектуры в задачах определенной тематики."
  },
  {
    "objectID": "3.team_work.html#типы-задач",
    "href": "3.team_work.html#типы-задач",
    "title": "Team work",
    "section": "Типы задач",
    "text": "Типы задач\n\nЗадачи обработки данных.\nЗадачи проведения исследований.\nВсопогательные задачи.\n\n\nЗадачи обработки данных появляются в основном на первых этапах исследования и связаны с очисткой и подготовкой датасета. Постановка такой задачи должна содержать:\n\nмотивацию для появления этой задачи, зачем она нужна, как будет использоваться результат;\nназвание предполагаемого(ых) датасета(ов) для выполнения, в процессе работы исполнитель может их изменить при необходимости(если поймет, что есть данные более подходящего формата);\nописание действий над данными: фильтрация, очистка, заполнение пропусков, объединение и тд.\nпри необходимости фиксируются параметры или же ссылки на участки кода, которые необходимо применить;\nдополнительная известная информация касающаяся данной задачи.\n\nЗадачи проведения исследований описывают постановку исследования, такие задачи составляют наибольшую часть всех задач и появляются на протяжении всего проекта. В описании карточки необходимо указать:\n\nнаправление исследования, в какой области мы копаемся;\nпроверяемую гипотезу в рамках исследования;\nожидаемый результат, что подтвердит выдвинутую гипотезу.\n\nВспомогательные задачи появляются на протяжении всего проекта, они связаны с различными дополнительными работами или исправлением багов.В постановке такой задачи описывается или баг, или работы которые надо провести. Для описания бага стоит отметить:\n\nВ чем заключается баг?\nКак его воспроизвести?\nГде проблема в коде? В отчете?\nКакие файлы надо изменить?\nЧто надо настроить и как?"
  },
  {
    "objectID": "3.team_work.html#defenition-of-done-dod",
    "href": "3.team_work.html#defenition-of-done-dod",
    "title": "Team work",
    "section": "Defenition of Done (DoD)",
    "text": "Defenition of Done (DoD)\n\nСоставлен отчет о проведенном исследовании.\nКод соответсвует принятым стандартам качества.\nДля новых функциональностей написаны тесты.\nПройдено ревью кода и исслдеования.\n\n\nDoD - Состояние задачи когда она готова. Членам команды так же важно понимать, что нужно сделать что бы считать задачу выполненой.\nЭто знание необходимо что бы понимать, какой объем работ нужно провести для выполнения задачи, помимо маого исследвоания, потому что, напоминаю, вы работаете в команде и важно не только провести исследвоание, но и составить для него опичание, которое позволило бы делиться знаниями с другими членами команды, привести в порядок код и оттестирвоать его.\nНа слайде привден пример что моет быть в DoD, в целом эта договреность формируется также командой и все члены команды должны понимать зачем им это нужно."
  },
  {
    "objectID": "2.replication_crisis.html#в-чем-заключается-кризис",
    "href": "2.replication_crisis.html#в-чем-заключается-кризис",
    "title": "Replication crisis",
    "section": "В чем заключается кризис?",
    "text": "В чем заключается кризис?\n\n\nМашинное обучение (МО) нашло применение в исследованиях всех областей науки и во многом заменило традиционную статистику. И хотя для анализа данных зачастую проще использовать именно МО, присущий этой технологии «подход чёрной коробки» вызывает серьёзные проблемы при интерпретации результатов.\nТермин «кризис воспроизводимости» означает, что тревожно большое количество результатов научных экспериментов не нашли своего подтверждения при проведении тех же манипуляций другими группами учёных. Это может означать, что результаты, полученные в ходе изначальных работ, ошибочны. Согласно данным одного анализа, до 85 % всех проведённых в мире исследовательских работ в области биомедицины не привели к значимым результатам."
  },
  {
    "objectID": "2.replication_crisis.html#научный-метод-проведения-исследований",
    "href": "2.replication_crisis.html#научный-метод-проведения-исследований",
    "title": "Replication crisis",
    "section": "Научный метод проведения исследований",
    "text": "Научный метод проведения исследований\n\n\n\n\n\n\n\n\n\nОбъективность\nВоспроизводимость\nВалидность\n\n\n\n\nСобственно в научном сообществе есть методология проведения исследваоний и познания. Называется она научный метод. Основными требвоаниями к которому являются объективность, воспроизводимость и валидность.\nОбъекти́вность — отношение к объекту (явлению) и его характеристикам, процессам, как к независимому от воли и желания человека. Объективность подразумевает наличие знаний как таковых об объекте (явлении). Устойчивость объективности зависит от количества и точности понимания различных параметров объекта и/или процессов явления.\nВоспроизводимость - главный принцип научного метода . Это означает, что результат, полученный в ходе эксперимента или наблюдательного исследования , должен быть снова достигнут с высокой степенью согласия, когда исследование повторяется с использованием одной и той же методологии разными исследователями. Только после одного или нескольких таких успешных повторений результат должен быть признан научным знанием.\nВали́дность — обоснованность и пригодность применения методик и результатов исследования в конкретных условиях. Более прикладное определение понятия «валидность» — мера соответствия методик и результатов исследования поставленным задачам.\nДавайте уделим чуть больше внимания воспроизводимости. Так как сегодня мы рассматриваем кризис воспроивзодимости."
  },
  {
    "objectID": "2.replication_crisis.html#какая-бывает-воспроизводимость",
    "href": "2.replication_crisis.html#какая-бывает-воспроизводимость",
    "title": "Replication crisis",
    "section": "Какая бывает воспроизводимость1?",
    "text": "Какая бывает воспроизводимость1?\n\nПовторяемость измерений(также сходимость результатов измерений, англ. Repeatability)\nПовторяемость исследований (англ. Replicability) (Different team, same experimental setup)\nВоспроизводимость (англ. Reproducibility)\n\n\n\nНа основании определений Ассоциации вычислительной техники я предлагаю принять следующие определения:\nПовторяемость измерений(также сходимость результатов измерений, англ. Repeatability) (Same team, same experimental setup): Результат может быть получен с заявленной точностью одной и той же командой, используя одну и ту же процедуру измерения, одну и ту же измерительную систему, при одинаковых рабочих условиях, в одном месте при нескольких испытаниях. Для вычислительных экспериментов это означает, что исследователь может надежно повторить собственное вычисление.\nПовторяемость исследований (англ. Replicability) (Different team, same experimental setup): Результат может быть получено с заявленной точностью другой командой с использованием той же процедуры измерения, той же измерительной системы, в тех же рабочих условиях, в том же или другом месте при нескольких испытаниях. Для вычислительных экспериментов это означает, что независимая группа может получить тот же результат, используя наработки автора, вплоть до его реализаций.\nВоспроизводимость (англ. Reproducibility): Результат может быть получено с заявленной точностью другой командой, другой измерительной системой, в другом месте на нескольких испытаниях. Для вычислительных экспериментов это означает, что независимая группа может получить тот же результат, используя артефакты, которые они разрабатывают полностью независимо.\n\n\n\nНа основании определений Ассоциации вычислительной техники"
  },
  {
    "objectID": "2.replication_crisis.html#что-такое-воспроизводимое-исследвоаниеви",
    "href": "2.replication_crisis.html#что-такое-воспроизводимое-исследвоаниеви",
    "title": "Replication crisis",
    "section": "Что такое воспроизводимое исследвоание(ВИ)",
    "text": "Что такое воспроизводимое исследвоание(ВИ)\n\n«Цель воспроизводимых исследований - привязать конкретные инструкции к анализу данных и экспериментальным данным, чтобы исследование можно было воссоздать, лучше понять и проверить».\n\n\nВоспроизводимые исследования (Reproducible research) - это термин, используемый в некоторых областях исследований для обозначения определенного способа проведения анализа, который предоставляет:\n\nинструменты преобразующие необработанные данные и метаданные в обработанные данные;\nинструменты выполняющие анализ данных;\nинструменты агрегирующие анализы в отчет.\n\nВ некоторый случаях указывают конкретно какие инструменты и шаги имеются в виду, это может быть программный продукт, публикации, определенные лабораторные условия и т.д.\nКогда предоставляются объекты анализа, например данные, и инструменты, а также алгоритмы последовательного решения задачи, это позволяет другим исследователям:\n\nвыполнять анализ, о котором не сообщалось первыми исследователями;\nпроверить правильность исследований, выполненных первыми исследователями;"
  },
  {
    "objectID": "2.replication_crisis.html#в-чем-причина-кризиса-воспроизводимости",
    "href": "2.replication_crisis.html#в-чем-причина-кризиса-воспроизводимости",
    "title": "Replication crisis",
    "section": "В чем причина кризиса воспроизводимости?",
    "text": "В чем причина кризиса воспроизводимости?\n\n\n\nнедостаточное понимание алгоритма ML.\nнедостаточное знакомство с исходными данными.\nневерная интерпретация результатов.\n\n\n \n\n\n\nНедостаточное понимание алгоритма — очень распространённая проблема в машинном обучении. Это серьезная проблема при работе с нейросетями ввиду множества параметров (зачастую для глубоких нейросетей количество параметров может составлять миллионы). Помимо этих параметров надо принимать в расчёт и гиперпараметры — такие как скорость обучения, метод инициализации, количество итераций, архитектура нейросети.\nДля решения проблемы мало осознать, что исследователь недостаточно хорошо понимает работу алгоритма. Как можно сравнить результаты, если в разных работах применялись отличающиеся по структуре нейронные сети? Многослойная нейронная сеть имеет очень сложную динамическую структуру. Поэтому даже добавление единственной переменной или смена одного гиперпараметра может значительно повлиять на результаты.\nПлохое понимание исходных данных также является серьёзной проблемой, но эта проблема существовала и во время работы с традиционными статистическими методами. Ошибки в сборе данных — такие как ошибки квантования, неточности считывания и использование замещающих переменных — самые распространённые затруднения. Субоптимальные данные всегда будут проблемой, но понимать, какой алгоритм применить к какому типу данных — невероятно важно, это значительно повлияет на результат.\nОшибочная оценка результатов может быть весьма распространена в научном мире. Одна из причин — видимая корреляция не всегда отражает реальную взаимосвязь. Есть несколько причин, почему переменные А и B могут коррелировать:\n\nA может изменяться при изменении B;\nB может изменяться при изменении A;\nA и B могут изменяться при изменении общей базовой переменной, C;\nкорреляция A и B может быть ложной. Продемонстрировать корреляцию двух значений легко, гораздо сложнее определить её причину. Погуглив «spurious correlations» (ложная корреляция), вы найдёте весьма интересные и забавные примеры, имеющие статистическое значение:\n\nсобственно на слайде вы модете видеть некоторые из них, например расходы США на науку, космос и технологии явно коррелируют с самоубийствами путем повешения, а от количества разводов в Мэне зависит потребеление маргарина на душу населения.\nВсё это может выглядеть забавными совпадениями, но смысл в том, что алгоритм машинного обучения, обработав эти переменные единым набором, воспримет их как взаимозависимые, не подвергая эту зависимость сомнению. То есть алгоритм будет неточным или ошибочным, поскольку ПО выделит в датасете паттерны, которых не существует в реальном мире. Это примеры ложных корреляций, которые в последние годы опасно распространились в связи с использованием наборов данных из тысяч переменных.\nТак же есть такие техники как p-hacking или форсирование кореляций.\nСуть p-hacking’а состоит в дотошном поиске в наборе данных статистически значимых корреляций и принятии их за научно обоснованные.\nЕщё одна проблема алгоритмов машинного обучения заключается в том, что алгоритм должен делать предположения. Алгоритм не может «ничего не найти». Это означает, что алгоритм либо найдёт способ интерпретировать данные независимо от того, насколько они соотносятся между собой, либо не придёт к какому-либо определённому заключению (обычно это означает, что алгоритм был неверно настроен или данные плохо подготовлены)."
  },
  {
    "objectID": "2.replication_crisis.html#правила-проведения-воспроизводимых-исследований",
    "href": "2.replication_crisis.html#правила-проведения-воспроизводимых-исследований",
    "title": "Replication crisis",
    "section": "Правила проведения воспроизводимых исследований",
    "text": "Правила проведения воспроизводимых исследований\n\nДля каждого полученного результата сохраните алгоритм его получения.\nИзбегайте этапов ручного управления данными или процессом.\nСохраните точные версии всех использованных внешних инструментов.\nИспользуйте контроль версий.\nХраните все промежуточные результаты в стандартизированном виде.\nДля алгоритмов использующих случайность записывайте их random_state.\nВсегда храните вместе с графиками данные.\nИерархический подход при генерировании результатов анализа.\nВсегда указывайте вместе текстовые утверждения и результаты исследования.\nОбеспечивайте доступность ваших результатов, данных и исследований.\n\n\n\nВажно знать каким образом вы получили те или иные результаты. Знание того, как вы перешли от необработанных данных к заключению, позволяет вам: защищать, обновлять, воспроизводить и передовать свои результаты исследвоаний.\nМожет возникнуть соблазн открыть файлы данных в редакторе и вручную исправить пару ошибок форматирования или удалить выбросы. Кроме того, современные редакторы позволяют легко форматировать файлы огромных размеров. Однако соблазну сократить ваш алгоритм следует сопротивляться. Ручная обработка данных - это скрытая манипуляция.\nВам необходимо задокументировать выпуск и версию всего используемого программного обеспечения, включая операционную систему. Незначительные изменения в программном обеспечении могут повлиять на результаты. В идеале вы должны настроить виртуальную машину или контейнер со всем программным обеспечением, используемым для запуска ваших скриптов. Это позволяет сделать снимок вашей аналитической экосистемы, что упрощает воспроизведение ваших результатов.\nДля отслеживания версий ваших скриптов следует использовать систему контроля версий, такую ​​как Git. Вы должны пометить (сделать снимок) текущее состояние скриптов и ссылаться на этот тег во всех получаемых вами результатах. Если вы затем решите изменить свои алгоритмы, что вы обязательно сделаете, можно будет вернуться во времени и получить точные сценарии, которые использовались для получения заданного результата.\nЕсли вы соблюдаете Правило № 1, в теории уже возможно воссоздать любые результаты на основе необработанных данных. Однако, хотя это может быть теоретически возможно, на практике могут быть ограничивающие факторы. Проблемы могут быть следующие:\n\n\nотсутствие ресурсов для запуска результатов с нуля (например, если использовались значительные вычислительные ресурсы кластера)\nотсутствие лицензий на некоторые инструменты, если использовались коммерческие инструменты\nнедостаточная техническая доступность некоторых инструментов\n\nВ этих случаях может быть полезно начать исследование с набора производных данных, которые уже могут представлять больше пользы или быть более удобными, чем необработанных данных. Хранение этих промежуточных наборов данных (например, в формате CSV) предоставляет больше возможностей для дальнейшего анализа и может упростить определение проблемных результатов, когда они ошибочны, поскольку нет необходимости все переделывать.\n\nОдна вещь, которую специалисты по данным часто не могут сделать - это установить исходные значения для своего анализа. Это делает невозможным точное воссоздание исследований машинного обучения. Многие алгоритмы машинного обучения включают стохастический элемент, и, хотя надежные результаты могут быть статистически воспроизводимыми, нет ничего, что можно было бы сравнить с теплым сиянием в глазах проверяющего при точном совпадении результатов.\nЕсли вы используете скриптовый язык программирования, ваши графики скорее всего генерируются автоматически. Однако, если вы используете такой инструмент, как Excel, убедитесь, что вы сохранили начальные данные. Это позволяет не только воспроизвести график, но также более детально просмотреть лежащие в основе данные. Также стоит всегда сохранять алгоритмы, которые вы использовали для получения график на основе которых вы потом приводите какие-либо утверждения.\nНаша задача как специалистов по обработке данных - обобщить данные в той или иной форме. Вот что включает в себя извлечение информации из данных. Однако резюмирование также является простым способом неправильного использования данных, поэтому важно, чтобы заинтересованные стороны могли разбить сводку на отдельные точки данных. Для каждого итогового результата укажите ссылку на данные, использованные для расчета итогового значения.\nВ конце работы результаты анализа данных оформляются в текстовом виде. И слова неточны. Иногда бывает трудно определить связь между выводами и анализом. Поскольку отчет часто является самой важной частью исследования, важно, чтобы его можно было связать с результатами и, в соответствии с правилом № 1, с исходными данными.\nВ коммерческих условиях может быть нецелесообразно предоставлять открытый доступ ко всем данным. Однако имеет смысл предоставить доступ другим пользователям в вашей организации. Облачные системы управления исходным кодом, такие как Bitbucket и GitHub, позволяют создавать частные репозитории, к которым могут получить доступ любые авторизованные коллеги."
  },
  {
    "objectID": "2.replication_crisis.html#заключение",
    "href": "2.replication_crisis.html#заключение",
    "title": "Replication crisis",
    "section": "Заключение",
    "text": "Заключение\nМашинное обучение в науке представляет проблему из-за того, что результаты недостаточно воспроизводимы. Однако учёные в курсе этой проблемы и работают над моделями ML, дающими более воспроизводимый и прозрачный результат. Настоящий прорыв произойдет, когда эта задача будет решена для нейросети.\nКак сказал физик Ричард Фейнман в своей речи перед выпускниками Калифорнийского технологического института в 1974 году:\n\n“Первый принцип науки заключается в том, чтобы не одурачить самого себя. И как раз себя-то одурачить проще всего.”"
  },
  {
    "objectID": "2.replication_crisis.html#список-источников",
    "href": "2.replication_crisis.html#список-источников",
    "title": "Replication crisis",
    "section": "Список источников",
    "text": "Список источников\n\nКризис машинного обучения в научных исследованиях\nReproducibility vs. Replicability: A Brief History of a Confused Terminology\nRepeatability, Repr)oducibility, and Replicability: Tackling the 3R challenge in biointerface science and engineering\n10 RULES FOR CREATING REPRODUCIBLE RESULTS IN DATA SCIENCE"
  },
  {
    "objectID": "1.entry.html#зачем-этот-курс",
    "href": "1.entry.html#зачем-этот-курс",
    "title": "Engineering practices in ML",
    "section": "Зачем этот курс?",
    "text": "Зачем этот курс?\n\nПознакомиться с повсеместными проблемами отрасли и их глубиной.\n\n\n\nУзнать их негативное влияние на разных уровнях (разработчик, команда, компания, индустрия).\n\n\n\n\nИзучить инструменты и практики позволяющие снизить это влияние.\n\n\n\n\nПоднять уровень компетенций в области ML."
  },
  {
    "objectID": "1.entry.html#почему-такое-название",
    "href": "1.entry.html#почему-такое-название",
    "title": "Engineering practices in ML",
    "section": "Почему такое название?",
    "text": "Почему такое название?\n\n\n\n\n\n\nСовременный data science и machine learning требуют написания большого количества кода. Прошли те дни когда все считалось на бумажках или в экселе. Теперь для разработки ML проектов требуется использование языков программирования общего пользования, библиотек и прочего. Собственно требуется “разработка ПО”. А это область давно и хорошо изучена."
  },
  {
    "objectID": "1.entry.html#инженерные-практики-в-разработке-по",
    "href": "1.entry.html#инженерные-практики-в-разработке-по",
    "title": "Engineering practices in ML",
    "section": "Инженерные практики в разработке ПО",
    "text": "Инженерные практики в разработке ПО\n\nTest driven development\nRefactoring\nDesign Improvement\nContinuous integration - continuous delivery\nPair programming\nAutomated tests\n\n\nВ области разработки ПО уже давно используются различные инженерные практики, общее принятые подходы для развития и увеличения производительности команды разработки ПО. Зачастую они упоминаются в различных agile методологиях, но на самом деле могут существовать отдельно. Применение таких практик позволяет поддерживать хорошее качество кода и архитектуры, быстрее поставлять новые фичи, повышать уровень развития команды. Собственно применение этих практик уже устоявшаяся вещь в индустрии разработки ПО."
  },
  {
    "objectID": "1.entry.html#какой-план",
    "href": "1.entry.html#какой-план",
    "title": "Engineering practices in ML",
    "section": "Какой план?",
    "text": "Какой план?\n\nПонимание проблематики\nОрганизация процесса в команде\nИнструменты воспроизводимости исследваоний\n\n\nСобственно каков план на этот курс. Сегдня мы бдуем разбираться с проблематикой. На следующих занятиях будем затрагивать темы организации процесса в команде и инструменты необходимые для воспроизводимости исследваоний."
  },
  {
    "objectID": "1.entry.html#i-dontt-like-jupyter-notebooks",
    "href": "1.entry.html#i-dontt-like-jupyter-notebooks",
    "title": "Engineering practices in ML",
    "section": "I dont’t like jupyter notebooks1",
    "text": "I dont’t like jupyter notebooks1\n\nскрытые состояния, которые можно забыть или испортить\nвозможность запускать код в произвольном порядке\nнет поддержки линтеров, форматеров и автокмплита\nне поддерживают модульность и переиспользование кода\nпоощрают написание не тестируемого кода\nприходиться писать смешанный код\nне удобны для версионировани в гите\nнет requirements\n\nРезюме: jupyter notebooks поощряют вредные привычки и плохие процессы, а также препятсвуют появлению хороших привычек.\n\n\n\nПервоисточник с конференции jupytercon - видео"
  },
  {
    "objectID": "1.entry.html#как-получить-зачет",
    "href": "1.entry.html#как-получить-зачет",
    "title": "Engineering practices in ML",
    "section": "Как получить зачет?",
    "text": "Как получить зачет?\n\\[0.4\\cdot\\text{ДЗ} + 0.4\\cdot\\text{ФП} + 0.2\\cdot\\text{Т}\\]\nДЗ - домашние задания.\nФП - финальная презентация.\nТ - Теоретический вопрос.\nСводная таблица будет обновляться."
  },
  {
    "objectID": "1.entry.html#домашнее-задание",
    "href": "1.entry.html#домашнее-задание",
    "title": "Engineering practices in ML",
    "section": "Домашнее задание",
    "text": "Домашнее задание\n\nВыбрать и опубликовать ML проект на GitHub.\nПеревести все jupyter notebook’и в скрипты (если это уже существующий проект, можете оставить jupyter notebook, но также создайте папку со скриптами).\nЗаполнить информацию о себе в сводной таблице\n\nДля тех, у кого нет своего проекта, советуем ознакомиться со следующими исследованиями, которые вы можете взять в качестве своего проекта, либо же составить свое исследование на их основе:\n\nA Statistical Analysis & ML workflow of Titanic\nTitanic: A complete approach for Data Scientists\nTitanic - Advanced Feature Engineering Tutorial\nExploratory Tutorial - Titanic\n\nДанное домашнее задание оценивается на 10 баллов, если оно сделано в срок. За каждый день опаздания в сдаче \\(-1\\) от исходной оценки."
  }
]