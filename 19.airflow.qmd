---
title: "Airflow"
author: "Lev Kovalenko"
format: 
    revealjs: 
        theme: dark
        self-contained: true
        echo: true
        source: true
---

##

![](images/airflow_logo.png)

:::{.notes}
Apache AirFlow — это open-source инструмент, который позволяет разрабатывать, планировать и осуществлять мониторинг сложных рабочих процессов. Главной особенностью является то, что для описания процессов используется язык программирования Python.
:::

## DAG

![](images/dag.png)

:::{.notes}
Процессы обработки данных, или пайплайны, в Airflow описываются при помощи DAG (Directed Acyclic Graph). Это смысловое объединение задач, которые необходимо выполнить в строго определенной последовательности согласно указанному расписанию. Визуально DAG выглядит как направленный ациклический граф, то есть граф, не имеющий циклических зависимостей.

В качестве узлов DAG выступают задачи (Task). Это непосредственно операции, применяемые к данным, например: загрузка данных из различных источников, их агрегирование, индексирование, очистка от дубликатов, сохранение полученных результатов и прочие ETL-процессы. На уровне кода задачи могут представлять собой Python-функции или Bash-скрипты.

За реализацию задач чаще всего отвечают операторы (Operator). Если задачи описывают, какие действия выполнять с данными, то операторы — как эти действия выполнять. По сути, это шаблон для выполнения задач.

Особую группу операторов составляют сенсоры (Sensor), которые позволяют прописывать реакцию на определенное событие. В качестве триггера может выступать наступление конкретного времени, получение некоторого файла или строки с данными, другой DAG/Task и так далее.
:::

## DAG Operators {.scrollable}

- PythonOperator
- BranchPythonOperator
- BashOperator
- SimpleHttpOperator
- MySqlOperator	
- PostgresOperator
- S3FileTransformOperator
- DockerOperator
- KubernetesPodOperator
- SqlSensor
- SlackAPIOperator
- EmailOperator
- DummyOperator

:::{.notes}
В AirFlow богатый выбор встроенных операторов. Кроме этого, доступно множество специальных операторов — путем установки пакетов поставщиков, поддерживаемых сообществом. Также возможно добавление пользовательских операторов — за счет расширения базового класса BaseOperator. Когда в проекте возникает часто используемый код, построенный на стандартных операторах, рекомендуется его преобразование в собственный оператор.

Примеры операторов приведены ниже.

Оператор	Назначение
PythonOperator	Исполнение Python-кода
BranchPythonOperator	Запуск задач в зависимости от выполнения заданного условия
BashOperator	Запуск Bash-скриптов
SimpleHttpOperator	Отправка HTTP-запросов
MySqlOperator	Отправка запросов к базе данных MySQL
PostgresOperator	Отправка запросов к базе данных PostgreSQL
S3FileTransformOperator	Загрузка данных из S3 во временную директорию в локальной файловой системе, преобразование согласно указанному сценарию и сохранение результатов обработки в S3
DockerOperator	Запуск Docker-контейнера под выполнение задачи
KubernetesPodOperator	Создание отдельного Pod под выполнение задачи. Используется совместно с K8s
SqlSensor	Проверка выполнения SQL-запроса
SlackAPIOperator	Отправка сообщений в Slack
EmailOperator	Отправка электронных писем
DummyOperator	«Пустой» оператор, который можно использовать для группировки задач

:::


## Airflow architecture

![](images/arch-diag-basic.png)

:::{.notes}
Основу архитектуры AirFlow составляют следующие компоненты:

Web Server — отвечает за пользовательский интерфейс, где предоставляется возможность настраивать DAG и их расписание, отслеживать статус их выполнения и так далее.
Metadata DB (база метаданных) — собственный репозиторий метаданных на базе библиотеки SqlAlchemy для хранения глобальных переменных, настроек соединений с источниками данных, статусов выполнения Task Instance, DAG Run и так далее. Требует установки совместимой с SqlAlchemy базы данных, например, MySQL или PostgreSQL.

Scheduler (планировщик) — служба, отвечающая за планирование в Airflow. Отслеживая все созданные Task и DAG, планировщик инициализирует Task Instance — по мере выполнения необходимых для их запуска условий. По умолчанию раз в минуту планировщик анализирует результаты парсинга DAG и проверяет, нет ли задач, готовых к запуску. Для выполнения активных задач планировщик использует указанный в настройках Executor.
Для определенных версий БД (PostgreSQL 9.6+ и MySQL 8+) поддерживается одновременная работа нескольких планировщиков — для максимальной отказоустойчивости.

Worker (рабочий) — отдельный процесс, в котором выполняются задачи. Размещение Worker — локально или на отдельной машине — определяется выбранным типом Executor.

Executor (исполнитель) — механизм, с помощью которого запускаются экземпляры задач. Работает в связке с планировщиком в рамках одного процесса. Поддерживаемые типы исполнителей приведены ниже.
:::

## Pros&Cons {.scrollable}

:::: {.columns }
 
::: {.column width="50%" }
**Pros**
 
- Не зависит от языка
- Возможность изоляции
- Распределенные вычесления
- Мониторинг экспериментов
- Простая параметризация и разделение на модули
 
:::
 
::: {.column width="50%"}
**Cons**
 
- DAG пишутся вами на python
- Нет ограничений на ресурсы
- Не умеет работать с git
- Не удобна для командной работы
 
:::
::::